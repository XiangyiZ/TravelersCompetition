while (a<0.05)
{
u = rnorm(3000)
x = x + u
a1 = shapiro.test(x)
a = a[2]
}
a = a[2];
{
u = rnorm(3000);
x = x + u;
a1 = shapiro.test(x);
a = a[2];
}
while (a<0.05)
{
u = rnorm(3000);
x = x + u;
a1 = shapiro.test(x);
a = a[2];
}
while (a<0.05)
{
u = rnorm(3000);
x = x + u;
a1 = shapiro.test(x);
a = a1[2];
}
n=0
a = 0
while (a<0.05)
{
u = rnorm(3000);
x = x + u;
a1 = shapiro.test(x);
a = a1[2];
}
a
plot(density(x))
n=0
a = 0
while (a<0.05)
{
u = rnorm(3000);
x = x + u;
n = n + 1;
a1 = shapiro.test(x);
a = a1[2];
}
n
a
n=0
a = 0
while (a<0.05)
{
u = runif(3000);
x = x + u;
n = n + 1;
a1 = shapiro.test(x);
a = a1[2];
}
a
n=0
a = 0
while (a<0.05)
{
u = runif(3000);
x = x + u;
n = n + 1;
a1 = shapiro.test(x);
a = a1[2];
}
a
n
x = 0
n = 0
a = 0
while (a<0.05)
{
u = runif(3000);
x = x + u;
n = n + 1;
a1 = shapiro.test(x);
a = a1[2];
}
n
a
plot(density(x))
t1 = rnorm(100000,mean = 5,sd = 3)
t2 = runif(100000,min = 3,max = 7)
plot(density(t2))
t1 = rnorm(100000,mean = 5,sd = 3)
t2 = runif(100000,min = 3,max = 7)
t = t1 + t2
t
plot(density(t2))
plot(density(t))
s1 = t[t<10]
length(s1)
length(s1)/100000
t = ifelse(t1>t2,t1,t2)
plot(density(t))
s1 = t[t<10]
length(s1)/100000
x = rnorm(20,mean = 12,sd = 6)
x
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
x = rnorm(20,mean = 12,sd = 6)
mean(x)
sd(x)
getwd()
diabetes = read.csv("diabetes.csv")
diabetes = read.csv("diabetes.csv")
getwd()
setwd('/home/senlyu')
diabetes = read.csv("diabetes.csv")
Glucose = diabetes$Glucose
BloodPressure = diabetes$BloodPressure
stG = (Glucose - mean(Glucose))/sd(Glucose)
stB = (BloodPressure - mean(BloodPressure))/sd(BloodPressure)
plot(density(stG))
lines(density(stB),col="blue")
p = c(0.1,0.2,0.9,0.9,0.96)
q1 = quantile(stG,probs = p)
q2 = quantile(stB,probs = p)
tstat = sum(abs(q1-q2))
tstat
f1 = function()
{
x1 = sample(stG,length(stG),replace = TRUE)
x2 = sample(stG,length(stG),replace = TRUE)
q1 = quantile(x1,probs = p)
q2 = quantile(x2,probs = p)
return(sum(abs(q1-q2)))
}
sdist = replicate(10000,f1())
plot(density(sdist))
abline(v=tstat,col="blue")
gap = abs(mean(sdist)-tstat)
abline(v=mean(sdist)-gap,col="red")
abline(v=mean(sdist)+gap,col="red")
s1 = sdist[sdist<mean(sdist)-gap|sdist>mean(sdist)+gap]
pvalue = length(s1)/length(sdist)
pvalue
sdist = replicate(10000,f1())
plot(density(sdist))
abline(v=tstat,col="blue")
gap = abs(mean(sdist)-tstat)
abline(v=mean(sdist)-gap,col="red")
s1 = sdist[sdist<mean(sdist)-gap]
pvalue = length(s1)/length(sdist)
pvalue
s1 = sdist[sdist<tstat]
pvalue = length(s1)/length(sdist)
pvalue
s1 = sdist[sdist>tstat]
pvalue = length(s1)/length(sdist)
pvalue
tstat
s1 = sdist[sdist>tstat]
pvalue = length(s1)/length(sdist)
pvalue
x = rnorm(n = 1000,mean = 0,sd = 1)
x = rnorm(n = 1000,mean = 0,sd = 1)
x
x1 = rnorm(n = 1000,mean = 0,sd = 1)
lambda = 0.5
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
lambda = 0.7
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
lambda = 0.8
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
y = x1 + x2
model1 = lm(y~x1,x2)
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
summary(model1)
summary(model2)
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
summary(model1)
summary(model2)
lambda = 0.7
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
y = x1 + x2
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
summary(model1)
summary(model2)
y = x1 + x2 + rnorm(n = 1000,mean = 0,sd = 0.01)
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
summary(model1)
summary(model2)
lambda = 0.8
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
y = x1 + x2 + rnorm(n = 1000,mean = 0,sd = 0.01)
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
summary(model1)
summary(model2)
yy = y[1:500]
xx1 = x1[1:500]
yy = y[1:500]
xx1 = x1[1:500]
xx2 = x2[1:500]
model1 = lm(y~x1+x2)
model2 = lm(y~x1)
model1 = lm(yy~xx1+xx2)
model2 = lm(yy~xx1)
summary(model1)
summary(model2)
model1
model1[0]
model1[1]
model1[1][1]
model1$coefficients[0]
model1$coefficients[1]
model1$coefficients[2]
yy1 = y[501:1000]
xx11 = x1[501:1000]
xx22 = x2[501:1000]
error1 = sum(yy1-model1$coefficients[0]+model1$coefficients[1]*xx11+model1$coefficients[2]*xx22)
error1
model1 = lm(yy~xx1+xx2)
model2 = lm(yy~xx1)
summary(model1)
summary(model2)
error1 = sum(yy1-model1$coefficients[0]+model1$coefficients[1]*xx11+model1$coefficients[2]*xx22)
error1
error2 = sum(yy1-model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22)
error2
error2 = sum((yy1-model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22)^2)
error1 = sum((yy1-model1$coefficients[0]+model1$coefficients[1]*xx11+model1$coefficients[2]*xx22)^2)
error1
error2 = sum((yy1-model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22)^2)
error2
x1 = rnorm(n = 1000,mean = 0,sd = 1)
lambda = 0.8
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
y = x1 + x2 + rnorm(n = 1000,mean = 0,sd = 0.01)
yy = y[1:500]
yy1 = y[501:1000]
xx1 = x1[1:500]
xx11 = x1[501:1000]
xx2 = x2[1:500]
xx22 = x2[501:1000]
model1 = lm(yy~xx1+xx2)
model2 = lm(yy~xx1)
summary(model1)
summary(model2)
error1 = sum((yy1-model1$coefficients[0]+model1$coefficients[1]*xx11+model1$coefficients[2]*xx22)^2)
error1
error2 = sum((yy1-model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22)^2)
error2
yy1-model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22
yy1
model2$coefficients[0]+model2$coefficients[1]*xx11+model2$coefficients[2]*xx22
model2$coefficients[0]
model2$coefficients[1]
error1 = sum((yy1-(model1$coefficients[1]+model1$coefficients[2]*xx11+model1$coefficients[3]*xx22))^2)
error1
error2 = sum((yy1-(model2$coefficients[1]+model2$coefficients[2]*xx11+model2$coefficients[3]*xx22))^2)
error2
error2 = sum((yy1-(model2$coefficients[1]+model2$coefficients[2]*xx11+model2$coefficients[3]*xx22))^2)
error2
model2$coefficients[1]
model2$coefficients[2]
error2 = sum((yy1-(model2$coefficients[1]+model2$coefficients[2]*xx11))^2)
error2
error1 = sum((yy1-(model1$coefficients[1]+model1$coefficients[2]*xx11+model1$coefficients[3]*xx22))^2)
error1
error2 = sum((yy1-(model2$coefficients[1]+model2$coefficients[2]*xx11))^2)
error2
summary(model2)
error2
summary(model1)
error1
lambda = 1
x2 = lambda*x1+(1-lambda)*rnorm(n = 1000,mean = 0,sd = 1)
cor(x1,x2)
y = x1 + x2 + rnorm(n = 1000,mean = 0,sd = 0.01)
yy = y[1:500]
yy1 = y[501:1000]
xx1 = x1[1:500]
xx11 = x1[501:1000]
xx2 = x2[1:500]
xx22 = x2[501:1000]
model1 = lm(yy~xx1+xx2)
model2 = lm(yy~xx1)
summary(model1)
summary(model2)
error1 = sum((yy1-(model1$coefficients[1]+model1$coefficients[2]*xx11+model1$coefficients[3]*xx22))^2)
error1
error2 = sum((yy1-(model2$coefficients[1]+model2$coefficients[2]*xx11))^2)
error2
summary(model1)
get_z_star = function(alpha) {
return(-qnorm(alpha / 2))
}
# Inputs:
#   z-star: The z-critical value
#   s: The standard error of the metric at N=1
#   d_min: The practical significance level
#   N: The sample size of each group of the experiment
# Returns: The beta value of the two-tailed test
get_beta = function(z_star, s, d_min, N) {
SE = s /  sqrt(N)
return(pnorm(z_star * SE, mean=d_min, sd=SE))
}
# Inputs:
#   s: The standard error of the metric with N=1 in each group
#   d_min: The practical significance level
#   Ns: The sample sizes to try
#   alpha: The desired alpha level of the test
#   beta: The desired beta level of the test
# Returns: The smallest N out of the given Ns that will achieve the desired
#          beta. There should be at least N samples in each group of the experiment.
#          If none of the given Ns will work, returns -1. N is the number of
#          samples in each group.
required_size = function(s, d_min, Ns=1:20000, alpha=0.05, beta=0.2) {
for (N in Ns) {
if (get_beta(get_z_star(alpha), s, d_min, N) <= beta) {
return(N)
}
}
return(-1)
}
required_size(s=0.0202, d_min=0.01, Ns=seq(10, 500000, 100))
required_size(s=0.0202, d_min=0.01, Ns=seq(10, 500000, 100), alpha=0.1667)
required_size(s=0.0549, d_min=0.01, Ns=seq(10, 500000, 100), alpha=0.1667)
required_size(s=0.1092, d_min=0.01, Ns=seq(10, 500000, 100), alpha=0.1667)
required_size(s=0.0202, d_min=0.01, alpha=0.1667)
required_size(s=0.0549, d_min=0.01,  alpha=0.1667)
required_size(s=0.1092, d_min=0.01,  alpha=0.1667)
required_size(s=0.0202, d_min=0.01, alpha=0.1667)
required_size(s=0.0549, d_min=0.01,  alpha=0.1667)
required_size(s=0.1092, d_min=0.0075,  alpha=0.1667)
required_size(s=0.00515, d_min=0.02, alpha=0.05)
required_size(s=0.0119, d_min=0.02,  alpha=0.05)
required_size(s=0.00515*sqrt(5000), d_min=0.02, alpha=0.05)
required_size(s=0.0119*sqrt(5000), d_min=0.02,  alpha=0.05)
required_size(s=0.0202*sqrt(5000), d_min=0.02, alpha=0.0167)
required_size(s=0.0202*sqrt(5000), d_min=0.01, alpha=0.0167)
required_size(s=0.0202*sqrt(5000), d_min=0.01, alpha=0.05)
required_size(s=0.0202*sqrt(5000), d_min=0.01)
required_size(s=0.0549*sqrt(5000), d_min=0.01,  alpha=0.05)
required_size(s=0.0202*sqrt(82.5), d_min=0.01)
required_size(s=0.0202*sqrt(82.5), d_min=0.01,alpha=0.0167)
required_size(s=0.0549*sqrt(155.66), d_min=0.01,  alpha=0.0167)
required_size(s=0.0549*sqrt(155), d_min=0.01,  alpha=0.0167)
required_size(s=0.156*sqrt(155.66), d_min=0.0075,  alpha=0.1667)
required_size(s=0.0202*sqrt(82.5), d_min=0.01,alpha=0.0167)
required_size(s=0.0549*sqrt(43.725), d_min=0.01,  alpha=0.0167)
required_size(s=0.156*sqrt(43.725), d_min=0.0075,  alpha=0.1667)
required_size(s=0.0156*sqrt(43.725), d_min=0.0075,  alpha=0.1667)
train = read.csv('Train.csv')
setwd("~/git/TravelersCompetition/data")
train = read.csv('Train.csv')
train$year =as.factor(train$year)
##################zip code (assign based on first three digits)
train$area = NA
hist(train$zip.code)
table(train$zip.code %/% 100)
train$area[train$zip.code %/% 100 ==150]="PA"
train$area[train$zip.code %/% 100 ==201]="DC"
train$area[train$zip.code %/% 100 ==500]="IA"
train$area[train$zip.code %/% 100 ==800]="CO"
train$area[train$zip.code %/% 100 ==801]="CO"
train$area[train$zip.code %/% 100 ==850]="AZ"
train$area[train$zip.code %/% 100 ==980]="wA"
train$area =as.factor(train$area)
train$zip.code=as.factor(train$zip.code)
train =train[,c(1:17,19,18)]
summary(train)
str(train)
par(mfrow=c(2,2))
for (i in (2:18)) {
if(class(train[,i])!='factor') {
boxplot(train[,i],main = colnames(train)[i])}
else {next}
}
#n.adults
hist(train$n.adults)
#nrow(subset(train,train$n.adults>6))
train1 = subset(train,train$n.adults<=6)
#n.children
hist(train$n.children)
#nrow(subset(train,train$n.children<=7))
train2 = subset(train1,train1$n.adults<=7)
#len.at.res
hist(train$len.at.res)
boxplot(train$len.at.res)
#nrow(subset(train,train$len.at.res>27))
train3 = subset(train2,train2$len.at.res<=27)
#ni.age
hist(train$ni.age)
#nrow(subset(train,train$ni.age>80))
train4 = subset(train3,train3$ni.age<=90)
#i=2
for (i in (2:18)) {
if(class(train4[,i])!='factor') {
if (sum(is.na(train4[,i]))!=0) {
train4[which(is.na(train4[,i])),i]=mean(train4[,i],na.rm=T)
}
}
else {next}
}
summary(train4[,-c(6,9,10,11,13,14,16,17,18)])
str(train)
#deal with categorical variables containing NA
summary(train4[,c(6,9,10,11,13,14,16,17,18)])
#i=6
for (i in (2:18)) {
if(class(train4[,i])=='factor') {
if (sum(is.na(train4[,i]))!=0) {
train4=subset(train4,!is.na(train4[,i]))
}
}
else {next}
}
summary(train4)
#dummy variable
colnames(train4)[c(6,9,10,11,13,14,18)]
fmla = as.formula(paste("~",paste(colnames(train4)[c(6,9,10,11,13,14,18)],collapse = "+"),sep = ""))
dummies = model.matrix(fmla,train4)[,-1]
dummies = as.data.frame(dummies)
train5 = cbind(dummies,train4[,-c(6,9,10,11,13,14,16,17,18)])
summary(train5)
#remove cancel -1 value
table(train$cancel)
train6 = train5[train5$cancel!=-1,]
summary(train6)
#############standardization
colnames(train6)
range01 = function(x){
(x-min(x))/(max(x)-min(x))
}
train6$tenure = range01(train6$tenure)
train6$n.adults=range01(train6$n.adults)
train6$n.children=range01(train6$n.children)
train6$premium=range01(train6$premium)
train6$len.at.res=range01(train6$len.at.res)
train6$ni.age=range01(train6$ni.age)
# proportion of our outcome variable
prop.table(table(train6$cancel))
############split train,validation and test
model =train6
install.packages("caTools")
library(caTools)
set.seed(123)
split_train = sample.split(model,SplitRatio = .6)
training_set = subset(model,split_train==TRUE)
validation = subset(model,split_train==FALSE)
split_train2 = sample.split(validation,SplitRatio = .5)
validation_set = subset(validation,split_train2==TRUE)
testing_set = subset(validation,split_train2==FALSE)
#####way 2:  model = as.data.frame(scale(model[,-c(18,27)]))
#model = cbind(model,train6[,27])
############model part
### 1. glm
formula = as.formula(paste("cancel~",paste(colnames(model)[-c(18,27)],collapse = "+"),sep = ""))
fit = glm(formula,training_set,family = "binomial")
summary(fit)
predicted_value = predict(fit,validation_set,type = "response")
predicted_value2 = predict(fit,testing_set,type = "response")
##########c-statistic
install.packages("ROCR")
library(ROCR)
pred_input = prediction(predicted_value,validation_set$cancel)
pred_input2 = prediction(predicted_value2,testing_set$cancel)
AUC =performance(pred_input,"auc")
print(AUC@y.values)
AUC =performance(pred_input2,"auc")
print(AUC@y.values)
### 2. glmnet
install.packages("caret")
library(caret)
predictname = as.matrix(training_set[-c(18,27)])
clonames(training_set)
colnames(training_set)
predicted_value = predict(fit2,validation_set)
predicted_value2 = predict(fit2,testing_set)
##########c-statistic
pred_input = prediction(predicted_value,validation_set$cancel)
pred_input2 = prediction(predicted_value2,testing_set$cancel)
AUC =performance(pred_input,"auc")
print(AUC@y.values)
AUC =performance(pred_input2,"auc")
print(AUC@y.values)
